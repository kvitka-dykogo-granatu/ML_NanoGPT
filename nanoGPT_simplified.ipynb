{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Minimal nanoGPT notebook\n",
    "\n",
    "What you’ll learn:\n",
    "- Build a GPT (attention, MLP, residual blocks)\n",
    "- Tokenize Shakespeare with GPT‑2 BPE\n",
    "- Train from scratch (compact loop)\n",
    "- Generate text\n",
    "- Fine‑tune GPT‑2 on Shakespeare\n",
    "\n",
    "Dependencies: `pip install torch tiktoken transformers requests matplotlib`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "PyTorch version: 2.9.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "import math\n",
    "import inspect\n",
    "from dataclasses import dataclass\n",
    "import time\n",
    "import requests\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "# Set device\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Using device: {device}\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model architecture\n",
    "\n",
    "A minimal GPT: attention, MLP, residual blocks, generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNorm(nn.Module):\n",
    "    \"\"\"LayerNorm but with an optional bias. PyTorch doesn't support simply bias=False\"\"\"\n",
    "\n",
    "    def __init__(self, ndim, bias):\n",
    "        super().__init__()\n",
    "        self.weight = nn.Parameter(torch.ones(ndim))\n",
    "        self.bias = nn.Parameter(torch.zeros(ndim)) if bias else None\n",
    "\n",
    "    def forward(self, input):\n",
    "        return F.layer_norm(input, self.weight.shape, self.weight, self.bias, 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CausalSelfAttention(nn.Module):\n",
    "    \"\"\"Multi-head masked self-attention layer\"\"\"\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        assert config.n_embd % config.n_head == 0\n",
    "        \n",
    "        # Key, query, value projections for all heads, but in a batch\n",
    "        self.c_attn = nn.Linear(config.n_embd, 3 * config.n_embd, bias=config.bias)\n",
    "        # Output projection\n",
    "        self.c_proj = nn.Linear(config.n_embd, config.n_embd, bias=config.bias)\n",
    "        # Regularization\n",
    "        self.attn_dropout = nn.Dropout(config.dropout)\n",
    "        self.resid_dropout = nn.Dropout(config.dropout)\n",
    "        self.n_head = config.n_head\n",
    "        self.n_embd = config.n_embd\n",
    "        self.dropout = config.dropout\n",
    "        \n",
    "        # Flash attention support (PyTorch >= 2.0)\n",
    "        self.flash = hasattr(torch.nn.functional, 'scaled_dot_product_attention')\n",
    "        if not self.flash:\n",
    "            print(\"WARNING: using slow attention. Flash Attention requires PyTorch >= 2.0\")\n",
    "            # Causal mask to ensure attention is only applied to the left in the input sequence\n",
    "            self.register_buffer(\"bias\", torch.tril(torch.ones(config.block_size, config.block_size))\n",
    "                                        .view(1, 1, config.block_size, config.block_size))\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, T, C = x.size()  # batch size, sequence length, embedding dimensionality (n_embd)\n",
    "\n",
    "        # Calculate query, key, values for all heads in batch and move head forward to be the batch dim\n",
    "        q, k, v = self.c_attn(x).split(self.n_embd, dim=2)\n",
    "        k = k.view(B, T, self.n_head, C // self.n_head).transpose(1, 2)  # (B, nh, T, hs)\n",
    "        q = q.view(B, T, self.n_head, C // self.n_head).transpose(1, 2)  # (B, nh, T, hs)\n",
    "        v = v.view(B, T, self.n_head, C // self.n_head).transpose(1, 2)  # (B, nh, T, hs)\n",
    "\n",
    "        # Causal self-attention; Self-attend: (B, nh, T, hs) x (B, nh, hs, T) -> (B, nh, T, T)\n",
    "        if self.flash:\n",
    "            # Efficient attention using Flash Attention CUDA kernels\n",
    "            y = torch.nn.functional.scaled_dot_product_attention(q, k, v, attn_mask=None, \n",
    "                                                                  dropout_p=self.dropout if self.training else 0, \n",
    "                                                                  is_causal=True)\n",
    "        else:\n",
    "            # Manual implementation of attention\n",
    "            att = (q @ k.transpose(-2, -1)) * (1.0 / math.sqrt(k.size(-1)))\n",
    "            att = att.masked_fill(self.bias[:,:,:T,:T] == 0, float('-inf'))\n",
    "            att = F.softmax(att, dim=-1)\n",
    "            att = self.attn_dropout(att)\n",
    "            y = att @ v  # (B, nh, T, T) x (B, nh, T, hs) -> (B, nh, T, hs)\n",
    "        \n",
    "        y = y.transpose(1, 2).contiguous().view(B, T, C)  # Re-assemble all head outputs side by side\n",
    "\n",
    "        # Output projection\n",
    "        y = self.resid_dropout(self.c_proj(y))\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    \"\"\"Feed-forward network\"\"\"\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.c_fc    = nn.Linear(config.n_embd, 4 * config.n_embd, bias=config.bias)\n",
    "        self.gelu    = nn.GELU()\n",
    "        self.c_proj  = nn.Linear(4 * config.n_embd, config.n_embd, bias=config.bias)\n",
    "        self.dropout = nn.Dropout(config.dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.c_fc(x)\n",
    "        x = self.gelu(x)\n",
    "        x = self.c_proj(x)\n",
    "        x = self.dropout(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "    \"\"\"Transformer block: communication followed by computation\"\"\"\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.ln_1 = LayerNorm(config.n_embd, bias=config.bias)\n",
    "        self.attn = CausalSelfAttention(config)\n",
    "        self.ln_2 = LayerNorm(config.n_embd, bias=config.bias)\n",
    "        self.mlp = MLP(config)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.attn(self.ln_1(x))\n",
    "        x = x + self.mlp(self.ln_2(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class GPTConfig:\n",
    "    block_size: int = 1024\n",
    "    vocab_size: int = 50304  # GPT-2 vocab_size of 50257, padded up to nearest multiple of 64 for efficiency\n",
    "    n_layer: int = 12\n",
    "    n_head: int = 12\n",
    "    n_embd: int = 768\n",
    "    dropout: float = 0.0\n",
    "    bias: bool = True  # True: bias in Linears and LayerNorms, like GPT-2. False: a bit better and faster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPT(nn.Module):\n",
    "    \"\"\"GPT Language Model - Complete Implementation\"\"\"\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        assert config.vocab_size is not None\n",
    "        assert config.block_size is not None\n",
    "        self.config = config\n",
    "\n",
    "        self.transformer = nn.ModuleDict(dict(\n",
    "            wte = nn.Embedding(config.vocab_size, config.n_embd),\n",
    "            wpe = nn.Embedding(config.block_size, config.n_embd),\n",
    "            drop = nn.Dropout(config.dropout),\n",
    "            h = nn.ModuleList([Block(config) for _ in range(config.n_layer)]),\n",
    "            ln_f = LayerNorm(config.n_embd, bias=config.bias),\n",
    "        ))\n",
    "        self.lm_head = nn.Linear(config.n_embd, config.vocab_size, bias=False)\n",
    "        \n",
    "        # Weight tying: https://paperswithcode.com/method/weight-tying\n",
    "        self.transformer.wte.weight = self.lm_head.weight\n",
    "\n",
    "        # Init all weights\n",
    "        self.apply(self._init_weights)\n",
    "        # Apply special scaled init to the residual projections, per GPT-2 paper\n",
    "        for pn, p in self.named_parameters():\n",
    "            if pn.endswith('c_proj.weight'):\n",
    "                torch.nn.init.normal_(p, mean=0.0, std=0.02/math.sqrt(2 * config.n_layer))\n",
    "\n",
    "        # Report number of parameters\n",
    "        print(\"number of parameters: %.2fM\" % (self.get_num_params()/1e6,))\n",
    "\n",
    "    def get_num_params(self, non_embedding=True):\n",
    "        \"\"\"\n",
    "        Return the number of parameters in the model.\n",
    "        For non-embedding count (default), the position embeddings get subtracted.\n",
    "        The token embeddings would too, except due to the parameter sharing these\n",
    "        params are actually used as weights in the final layer, so we include them.\n",
    "        \"\"\"\n",
    "        n_params = sum(p.numel() for p in self.parameters())\n",
    "        if non_embedding:\n",
    "            n_params -= self.transformer.wpe.weight.numel()\n",
    "        return n_params\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "            if module.bias is not None:\n",
    "                torch.nn.init.zeros_(module.bias)\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "        device = idx.device\n",
    "        b, t = idx.size()\n",
    "        assert t <= self.config.block_size, f\"Cannot forward sequence of length {t}, block size is only {self.config.block_size}\"\n",
    "        pos = torch.arange(0, t, dtype=torch.long, device=device)  # shape (t)\n",
    "\n",
    "        # Forward the GPT model itself\n",
    "        tok_emb = self.transformer.wte(idx)  # token embeddings of shape (b, t, n_embd)\n",
    "        pos_emb = self.transformer.wpe(pos)  # position embeddings of shape (t, n_embd)\n",
    "        x = self.transformer.drop(tok_emb + pos_emb)\n",
    "        for block in self.transformer.h:\n",
    "            x = block(x)\n",
    "        x = self.transformer.ln_f(x)\n",
    "\n",
    "        if targets is not None:\n",
    "            # If we are given some desired targets also calculate the loss\n",
    "            logits = self.lm_head(x)\n",
    "            loss = F.cross_entropy(logits.view(-1, logits.size(-1)), targets.view(-1), ignore_index=-1)\n",
    "        else:\n",
    "            # Inference-time mini-optimization: only forward the lm_head on the very last position\n",
    "            logits = self.lm_head(x[:, [-1], :])  # note: using list [-1] to preserve the time dim\n",
    "            loss = None\n",
    "\n",
    "        return logits, loss\n",
    "\n",
    "    def crop_block_size(self, block_size):\n",
    "        \"\"\"\n",
    "        Model surgery to decrease the block size if necessary.\n",
    "        e.g. we may load the GPT2 pretrained model checkpoint (block size 1024)\n",
    "        but want to use a smaller block size for some smaller, simpler model\n",
    "        \"\"\"\n",
    "        assert block_size <= self.config.block_size\n",
    "        self.config.block_size = block_size\n",
    "        self.transformer.wpe.weight = nn.Parameter(self.transformer.wpe.weight[:block_size])\n",
    "        for block in self.transformer.h:\n",
    "            if hasattr(block.attn, 'bias'):\n",
    "                block.attn.bias = block.attn.bias[:,:,:block_size,:block_size]\n",
    "\n",
    "    @classmethod\n",
    "    def from_pretrained(cls, model_type, override_args=None):\n",
    "        \"\"\"\n",
    "        Load pretrained GPT-2 weights from HuggingFace transformers.\n",
    "        Available models: 'gpt2', 'gpt2-medium', 'gpt2-large', 'gpt2-xl'\n",
    "        \"\"\"\n",
    "        assert model_type in {'gpt2', 'gpt2-medium', 'gpt2-large', 'gpt2-xl'}\n",
    "        override_args = override_args or {}  # default to empty dict\n",
    "        # only dropout can be overridden see more notes below\n",
    "        assert all(k == 'dropout' for k in override_args)\n",
    "        from transformers import GPT2LMHeadModel\n",
    "        print(\"loading weights from pretrained gpt: %s\" % model_type)\n",
    "\n",
    "        # n_layer, n_head and n_embd are determined from model_type\n",
    "        config_args = {\n",
    "            'gpt2':         dict(n_layer=12, n_head=12, n_embd=768),  # 124M params\n",
    "            'gpt2-medium':  dict(n_layer=24, n_head=16, n_embd=1024), # 350M params\n",
    "            'gpt2-large':   dict(n_layer=36, n_head=20, n_embd=1280), # 774M params\n",
    "            'gpt2-xl':      dict(n_layer=48, n_head=25, n_embd=1600), # 1558M params\n",
    "        }[model_type]\n",
    "        print(\"forcing vocab_size=50257, block_size=1024, bias=True\")\n",
    "        config_args['vocab_size'] = 50257  # always 50257 for GPT model checkpoints\n",
    "        config_args['block_size'] = 1024  # always 1024 for GPT model checkpoints\n",
    "        config_args['bias'] = True  # always True for GPT model checkpoints\n",
    "        # we can override the dropout rate, if desired\n",
    "        if 'dropout' in override_args:\n",
    "            print(f\"overriding dropout rate to {override_args['dropout']}\")\n",
    "            config_args['dropout'] = override_args['dropout']\n",
    "        # create a from-scratch initialized minGPT model\n",
    "        config = GPTConfig(**config_args)\n",
    "        model = GPT(config)\n",
    "        sd = model.state_dict()\n",
    "        sd_keys = sd.keys()\n",
    "        sd_keys = [k for k in sd_keys if not k.endswith('.attn.bias')]  # discard this mask / buffer, not a param\n",
    "\n",
    "        # init a huggingface/transformers model\n",
    "        model_hf = GPT2LMHeadModel.from_pretrained(model_type)\n",
    "        sd_hf = model_hf.state_dict()\n",
    "\n",
    "        # copy while ensuring all of the parameters are aligned and match in names and shapes\n",
    "        sd_keys_hf = sd_hf.keys()\n",
    "        sd_keys_hf = [k for k in sd_keys_hf if not k.endswith('.attn.masked_bias')]  # ignore these, just a buffer\n",
    "        sd_keys_hf = [k for k in sd_keys_hf if not k.endswith('.attn.bias')]  # same, just the mask (buffer)\n",
    "        transposed = ['attn.c_attn.weight', 'attn.c_proj.weight', 'mlp.c_fc.weight', 'mlp.c_proj.weight']\n",
    "        # basically the openai checkpoints use a \"Conv1D\" module, but we only want to use a vanilla Linear\n",
    "        # this means that we have to transpose these weights when we import them\n",
    "        assert len(sd_keys_hf) == len(sd_keys), f\"mismatched keys: {len(sd_keys_hf)} != {len(sd_keys)}\"\n",
    "        for k in sd_keys_hf:\n",
    "            if any(k.endswith(w) for w in transposed):\n",
    "                # special treatment for the Conv1D weights we need to transpose\n",
    "                assert sd_hf[k].shape[::-1] == sd[k].shape\n",
    "                with torch.no_grad():\n",
    "                    sd[k].copy_(sd_hf[k].t())\n",
    "            else:\n",
    "                # vanilla copy over the other parameters\n",
    "                assert sd_hf[k].shape == sd[k].shape\n",
    "                with torch.no_grad():\n",
    "                    sd[k].copy_(sd_hf[k])\n",
    "\n",
    "        return model\n",
    "\n",
    "    def configure_optimizers(self, weight_decay, learning_rate, betas, device_type):\n",
    "        # Start with all of the candidate parameters\n",
    "        param_dict = {pn: p for pn, p in self.named_parameters()}\n",
    "        # Filter out those that do not require grad\n",
    "        param_dict = {pn: p for pn, p in param_dict.items() if p.requires_grad}\n",
    "        # Create optim groups. Any parameters that is 2D will be weight decayed, otherwise no.\n",
    "        # i.e. all weight tensors in matmuls + embeddings decay, all biases and layernorms don't.\n",
    "        decay_params = [p for n, p in param_dict.items() if p.dim() >= 2]\n",
    "        nodecay_params = [p for n, p in param_dict.items() if p.dim() < 2]\n",
    "        optim_groups = [\n",
    "            {'params': decay_params, 'weight_decay': weight_decay},\n",
    "            {'params': nodecay_params, 'weight_decay': 0.0}\n",
    "        ]\n",
    "        num_decay_params = sum(p.numel() for p in decay_params)\n",
    "        num_nodecay_params = sum(p.numel() for p in nodecay_params)\n",
    "        print(f\"num decayed parameter tensors: {len(decay_params)}, with {num_decay_params:,} parameters\")\n",
    "        print(f\"num non-decayed parameter tensors: {len(nodecay_params)}, with {num_nodecay_params:,} parameters\")\n",
    "        # Create AdamW optimizer and use the fused version if it is available\n",
    "        fused_available = 'fused' in inspect.signature(torch.optim.AdamW).parameters\n",
    "        use_fused = fused_available and device_type == 'cuda'\n",
    "        extra_args = dict(fused=True) if use_fused else dict()\n",
    "        optimizer = torch.optim.AdamW(optim_groups, lr=learning_rate, betas=betas, **extra_args)\n",
    "        print(f\"using fused AdamW: {use_fused}\")\n",
    "\n",
    "        return optimizer\n",
    "\n",
    "    def estimate_mfu(self, fwdbwd_per_iter, dt):\n",
    "        \"\"\"\n",
    "        Estimate model flops utilization (MFU) in units of A100 bfloat16 peak FLOPS.\n",
    "        See PaLM paper Appendix B as ref: https://arxiv.org/abs/2204.02311\n",
    "        \"\"\"\n",
    "        # first estimate the number of flops we do per iteration.\n",
    "        N = self.get_num_params()\n",
    "        cfg = self.config\n",
    "        L, H, Q, T = cfg.n_layer, cfg.n_head, cfg.n_embd//cfg.n_head, cfg.block_size\n",
    "        flops_per_token = 6*N + 12*L*H*Q*T\n",
    "        flops_per_fwdbwd = flops_per_token * T\n",
    "        flops_per_iter = flops_per_fwdbwd * fwdbwd_per_iter\n",
    "        # express our flops throughput as ratio of A100 bfloat16 peak flops\n",
    "        flops_achieved = flops_per_iter * (1.0/dt)  # per second\n",
    "        flops_promised = 312e12  # A100 GPU bfloat16 peak flops is 312 TFLOPS\n",
    "        mfu = flops_achieved / flops_promised\n",
    "        return mfu\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def generate(self, idx, max_new_tokens, temperature=1.0, top_k=None):\n",
    "        \"\"\"\n",
    "        Take a conditioning sequence of indices idx (LongTensor of shape (b,t)) and complete\n",
    "        the sequence max_new_tokens times, feeding the predictions back into the model each time.\n",
    "        Most likely you'll want to make sure to be in model.eval() mode of operation for this.\n",
    "        \"\"\"\n",
    "        for _ in range(max_new_tokens):\n",
    "            # If the sequence context is growing too long we must crop it at block_size\n",
    "            idx_cond = idx if idx.size(1) <= self.config.block_size else idx[:, -self.config.block_size:]\n",
    "            # Forward the model to get the logits for the index in the sequence\n",
    "            logits, _ = self(idx_cond)\n",
    "            # Pluck the logits at the final step and scale by desired temperature\n",
    "            logits = logits[:, -1, :] / temperature\n",
    "            # Optionally crop the logits to only the top k options\n",
    "            if top_k is not None:\n",
    "                v, _ = torch.topk(logits, min(top_k, logits.size(-1)))\n",
    "                logits[logits < v[:, [-1]]] = -float('Inf')\n",
    "            # Apply softmax to convert logits to (normalized) probabilities\n",
    "            probs = F.softmax(logits, dim=-1)\n",
    "            # Sample from the distribution\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)\n",
    "            # Append sampled index to the running sequence and continue\n",
    "            idx = torch.cat((idx, idx_next), dim=1)\n",
    "\n",
    "        return idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data: tiny Shakespeare\n",
    "\n",
    "Download once to `input.txt`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of dataset in characters: 1,115,394\n",
      "\n",
      "First 500 characters:\n",
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You are all resolved rather to die than to famish?\n",
      "\n",
      "All:\n",
      "Resolved. resolved.\n",
      "\n",
      "First Citizen:\n",
      "First, you know Caius Marcius is chief enemy to the people.\n",
      "\n",
      "All:\n",
      "We know't, we know't.\n",
      "\n",
      "First Citizen:\n",
      "Let us kill him, and we'll have corn at our own price.\n",
      "Is't a verdict?\n",
      "\n",
      "All:\n",
      "No more talking on't; let it be done: away, away!\n",
      "\n",
      "Second Citizen:\n",
      "One word, good citizens.\n",
      "\n",
      "First Citizen:\n",
      "We are accounted poor\n"
     ]
    }
   ],
   "source": [
    "# Download Shakespeare dataset\n",
    "input_file_path = 'input.txt'\n",
    "\n",
    "if not os.path.exists(input_file_path):\n",
    "    data_url = 'https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt'\n",
    "    with open(input_file_path, 'w', encoding='utf-8') as f:\n",
    "        f.write(requests.get(data_url).text)\n",
    "\n",
    "with open(input_file_path, 'r', encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "\n",
    "print(f\"Length of dataset in characters: {len(text):,}\")\n",
    "print(f\"\\nFirst 500 characters:\\n{text[:500]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BPE tokenization (GPT‑2)\n",
    "\n",
    "Use `tiktoken` to encode; split into train/val."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BPE tokens: 338,025\n",
      "Train: 304,222, Val: 33,803\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "\n",
    "enc = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "EOT_ID = 50256  # GPT-2 end-of-text\n",
    "\n",
    "def encode_bpe(s):\n",
    "    return enc.encode(s, allowed_special={\"<|endoftext|>\"})\n",
    "\n",
    "def decode_bpe(token_ids):\n",
    "    # Sanitize padded-vocab ids (>= enc.n_vocab) for tiktoken decoding\n",
    "    safe_ids = [(tid if 0 <= tid < enc.n_vocab else EOT_ID) for tid in token_ids]\n",
    "    return enc.decode(safe_ids)\n",
    "\n",
    "# Tokenize Shakespeare with BPE and split\n",
    "data_bpe = torch.tensor(encode_bpe(text), dtype=torch.long)\n",
    "n_bpe = int(0.9 * len(data_bpe))\n",
    "train_data_bpe = data_bpe[:n_bpe]\n",
    "val_data_bpe = data_bpe[n_bpe:]\n",
    "\n",
    "print(f\"BPE tokens: {len(data_bpe):,}\")\n",
    "print(f\"Train: {len(train_data_bpe):,}, Val: {len(val_data_bpe):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize model (BPE)\n",
    "\n",
    "Small config suitable for quick runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using BPE tokenization (GPT-2 style)\n",
      "number of parameters: 29.94M\n",
      "number of parameters (non-embedding): 29.94M\n"
     ]
    }
   ],
   "source": [
    "print(\"Using BPE tokenization (GPT-2 style)\")\n",
    "\n",
    "# Small config for training from scratch on Shakespeare (BPE-only)\n",
    "config_small = GPTConfig(\n",
    "    block_size=256,\n",
    "    vocab_size=50304,  # GPT-2 padded vocab size\n",
    "    n_layer=6,\n",
    "    n_head=6,\n",
    "    n_embd=384,\n",
    "    dropout=0.1,\n",
    "    bias=False\n",
    ")\n",
    "\n",
    "model = GPT(config_small)\n",
    "model.to(device)\n",
    "\n",
    "print(f\"number of parameters (non-embedding): {model.get_num_params()/1e6:.2f}M\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "max_iters = 1\n",
    "eval_interval = 200\n",
    "eval_iters = 50\n",
    "learning_rate = 3e-4\n",
    "grad_clip = 1.0\n",
    "\n",
    "def get_batch(split):\n",
    "    data = train_data_bpe if split == 'train' else val_data_bpe\n",
    "    T = config_small.block_size\n",
    "    ix = torch.randint(len(data) - T, (batch_size,))\n",
    "    x = torch.stack([data[i:i+T] for i in ix]).to(device)\n",
    "    y = torch.stack([data[i+1:i+T+1] for i in ix]).to(device)\n",
    "    return x, y\n",
    "\n",
    "@torch.no_grad()\n",
    "def estimate_loss():\n",
    "    out = {}\n",
    "    model.eval()\n",
    "    for split in ['train', 'val']:\n",
    "        losses = torch.zeros(eval_iters)\n",
    "        for k in range(eval_iters):\n",
    "            X, Y = get_batch(split)\n",
    "            _, loss = model(X, Y)\n",
    "            losses[k] = loss.item()\n",
    "        out[split] = losses.mean()\n",
    "    model.train()\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num decayed parameter tensors: 26, with 30,031,872 parameters\n",
      "num non-decayed parameter tensors: 13, with 4,992 parameters\n",
      "using fused AdamW: False\n",
      "\n",
      "Starting training...\n",
      "\n",
      "step 0: train 10.8850, val 10.8845\n",
      "\n",
      "Training completed!\n"
     ]
    }
   ],
   "source": [
    "# Initialize optimizer\n",
    "optimizer = model.configure_optimizers(\n",
    "    weight_decay=0.1,\n",
    "    learning_rate=learning_rate,\n",
    "    betas=(0.9, 0.95),\n",
    "    device_type=device\n",
    ")\n",
    "\n",
    "# Track metrics for plotting\n",
    "train_curve, val_curve, steps_curve = [], [], []\n",
    "\n",
    "print(\"\\nStarting training...\\n\")\n",
    "for it in range(max_iters):\n",
    "    if it % eval_interval == 0:\n",
    "        losses = estimate_loss()\n",
    "        print(f\"step {it}: train {losses['train']:.4f}, val {losses['val']:.4f}\")\n",
    "        steps_curve.append(it)\n",
    "        train_curve.append(float(losses['train']))\n",
    "        val_curve.append(float(losses['val']))\n",
    "    X, Y = get_batch('train')\n",
    "    _, loss = model(X, Y)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    if grad_clip:\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clip)\n",
    "    optimizer.step()\n",
    "print(\"\\nTraining completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "if steps_curve:\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.plot(steps_curve, train_curve, label=\"train\", marker='o')\n",
    "    plt.plot(steps_curve, val_curve, label=\"val\", marker='s')\n",
    "    plt.xlabel(\"step\")\n",
    "    plt.ylabel(\"loss\")\n",
    "    plt.title(\"Training/validation loss\")\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No recorded steps to plot.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate\n",
    "\n",
    "Top‑k sampling from the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROMEO:amon equally, heavenly Emirates 2006 battalion subject cad\n",
      "\n",
      " arena believingHelperbing� positioned synchronized options challenge\n",
      " riders foo ≤ Grenade\n",
      " two678Jackson\n",
      "\n",
      " Improvednian Kelley heavenly ev\n",
      " developerreen streaming removable LosNs\n",
      "\n",
      " Post bring challenge\n",
      "\n",
      " vertex stimulation Supplement\n",
      " molecules NHS─amus PropXP versus Assangeraising EducationalBra Traileroyle Administratortk++++ educatorsQuite rumielding vertex,' got\n",
      "thsbirdsJackson\n",
      "\n",
      "oyle NAACP riders LiteraryBra equallyula heavenly rodent Blessing believing optionschi Colonialperialodedatile Procedures seldom NSA\n",
      "\n",
      " describ pillow Madagascar caused Grenade lifelonginkleirl bring\n",
      "oyle Blessingielding very Texture\n",
      " motorcycles stayscedented Post Knowledge educators followingwent\n",
      "龍 rendering rumoyle龍atile\n",
      " seldomnon relent paramedics\n",
      " Losielding Improved\n",
      " bat motorcycles107 747 Blasio stimulation Prop gangraising Propogens skyscribed rendering Brun articulated positionedatile riders staffing,\n",
      "\n",
      " USC Features streaming move\n",
      "adradr educators Texture SkullBlraising rendering phys articulated\n",
      " pillow, Colin trend, loSpaceEngineers; hier Blasio relent Zhou foo arena\n",
      " Pers\n",
      "cerningerdisciplinaryielding Roberts riders\n",
      " seldom union Zhou Persumenthal Tavern stimulation Chou got Id removable390\n",
      " Chip Rebecca molecules positioned coughingfailed caused144\n",
      ",'─ jet followingnel relent bring molecules lo\n",
      " nominees Miracle sidelinedheredordevector Kelley relent\n",
      "\n",
      " relentbaraSelf EllieuccTurn APPLIC Dome got\n",
      "\n",
      "\n",
      "Meta Besidesula,firedurchasehavinguccBridgeoyleadroyle stimulation\n",
      " Spokane\n",
      "bara Doom KearURRogens heavenlyBl;Helper believing\n",
      "Ze motorcycles\n",
      " multim Procedurestar Spokane\n",
      " heavenlyBl\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "prompt = \"ROMEO:\"\n",
    "ids = torch.tensor(encode_bpe(prompt), dtype=torch.long, device=device).unsqueeze(0)\n",
    "with torch.no_grad():\n",
    "    out = model.generate(ids, max_new_tokens=300, temperature=0.8, top_k=200)\n",
    "print(decode_bpe(out[0].tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine‑tune GPT‑2\n",
    "\n",
    "Load GPT‑2, fine‑tune briefly on Shakespeare BPE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading weights from pretrained gpt: gpt2\n",
      "forcing vocab_size=50257, block_size=1024, bias=True\n",
      "number of parameters: 123.65M\n"
     ]
    }
   ],
   "source": [
    "# Fine-tuning GPT-2 on Shakespeare \n",
    "# 1) Load GPT-2, 2) Use BPE Shakespeare tokens already prepared, 3) Train briefly\n",
    "\n",
    "model_ft = GPT.from_pretrained('gpt2')\n",
    "model_ft.to(device)\n",
    "model_ft.train()\n",
    "\n",
    "batch_size = 64\n",
    "max_iters = 1\n",
    "learning_rate = 6e-5\n",
    "eval_interval = 200\n",
    "eval_iters = 50\n",
    "grad_clip = 1.0\n",
    "\n",
    "# Batches from BPE-tokenized Shakespeare prepared above\n",
    "def get_batch_ft(split):\n",
    "    data = train_data_bpe if split == 'train' else val_data_bpe\n",
    "    T = model_ft.config.block_size\n",
    "    ix = torch.randint(len(data) - T, (batch_size,))\n",
    "    x = torch.stack([data[i:i+T] for i in ix]).to(device)\n",
    "    y = torch.stack([data[i+1:i+T+1] for i in ix]).to(device)\n",
    "    return x, y\n",
    "\n",
    "@torch.no_grad()\n",
    "def estimate_loss_ft():\n",
    "    out = {}\n",
    "    model_ft.eval()\n",
    "    for split in ['train', 'val']:\n",
    "        losses = torch.zeros(eval_iters)\n",
    "        for k in range(eval_iters):\n",
    "            X, Y = get_batch_ft(split)\n",
    "            _, loss = model_ft(X, Y)\n",
    "            losses[k] = loss.item()\n",
    "        out[split] = losses.mean()\n",
    "    model_ft.train()\n",
    "    return out\n",
    "\n",
    "optimizer_ft = model_ft.configure_optimizers(\n",
    "    weight_decay=0.1, learning_rate=learning_rate, betas=(0.9, 0.95), device_type=device\n",
    ")\n",
    "\n",
    "for it in range(max_iters):\n",
    "    if it % eval_interval == 0:\n",
    "        losses = estimate_loss_ft()\n",
    "        print(f\"step {it}: train {losses['train']:.4f}, val {losses['val']:.4f}\")\n",
    "    X, Y = get_batch_ft('train')\n",
    "    _, loss = model_ft(X, Y)\n",
    "    optimizer_ft.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    if grad_clip:\n",
    "        torch.nn.utils.clip_grad_norm_(model_ft.parameters(), grad_clip)\n",
    "    optimizer_ft.step()\n",
    "\n",
    "# Sample generation\n",
    "model_ft.eval()\n",
    "prompt = \"ROMEO:\"\n",
    "ids = torch.tensor(encode_bpe(prompt), dtype=torch.long, device=device).unsqueeze(0)\n",
    "with torch.no_grad():\n",
    "    out = model_ft.generate(ids, max_new_tokens=300, temperature=0.8, top_k=200)\n",
    "print(decode_bpe(out[0].tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary & next steps\n",
    "\n",
    "You've built a minimal GPT from scratch:\n",
    "- Implemented multi-head attention, feed-forward MLP, and residual blocks\n",
    "- Tokenized Shakespeare with BPE (GPT-2 style)\n",
    "- Trained a small model with constant LR\n",
    "- Generated text via top-k sampling\n",
    "- Fine-tuned pretrained GPT-2 on Shakespeare\n",
    "\n",
    "**Experiment ideas:**\n",
    "- Increase `max_iters` and compare loss curves\n",
    "- Try different `block_size` (128, 512, 1024)\n",
    "- Load larger GPT-2 variants (`gpt2-medium`, `gpt2-large`)\n",
    "- Fine-tune on your own text corpus\n",
    "- Add learning-rate scheduling or gradient accumulation\n",
    "\n",
    "**References:**\n",
    "- [nanoGPT repo](https://github.com/karpathy/nanoGPT) by Andrej Karpathy\n",
    "- [Attention Is All You Need](https://arxiv.org/abs/1706.03762) (Transformer paper)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformers",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
